---
title: QEUR23_CHRLTM35 : （STEP2-option） UnslothのFineTuningモデル済でRAGをやってみました
date: 2024-08-13
tags: ["QEUシステム", "メトリックス", "Python言語", "LLM", "データセット", "Fine-tuning", "イノベーション","Mistral Nemo"]
excerpt: LLMのファインチューニングを最適化する
---

## QEUR23_CHRLTM35 : （STEP2-option） UnslothのFineTuningモデル済でRAGをやってみました

### ～ よく言うと、本件は「発展途上」です ～

D先生（設定年齢65歳）： “そういえば、Unslothによりファインチューニングをしたモデルで、さらにRAG(Llangachain-Lllama_index)推論をしてみた事例って、あまり見かけないですね。”

![imageJRF2-35-1](/2024-08-13-QEUR23_CHRLTM35/imageJRF2-35-1.jpg)

QEU:FOUNDER（設定年齢65歳） ： “はっきりいって、いい・・・？ホント、**「RAGとUnslothは相性がわるい」**んですよ。技術的な意味では、定石になっているRAGのコードにUnslothのモデルを無条件に入れることができないこと。あとは、**プロンプト・エンジニアリングの問題**かな。”

D先生： “ものすごい時間をかけて、トライ・エラーをしたんでしょう？”

QEU:FOUNDER ： “もちろん！今回だけでなく、ず～っと前からトライを続け、失敗してきましたからね。Predibaseにしろ、Cohereにしろ、finetuneとRAGをセットにして売っているが、その**適用範囲がとても限定されています**。その意味がやっと分かりました。”

![imageJRF2-35-2](/2024-08-13-QEUR23_CHRLTM35/imageJRF2-35-2.jpg)

D先生： “ほとんどのオンラインで行うfinetuningサービスは、とてもシンプルなデータ（↑）構成を推薦していますよね。それには、**「次のステップにはRAGがあるので、これぐらいにしておけ」**という背景があるのか・・・。”

QEU:FOUNDER ： “今回は、パフォーマンスからいって「大失敗」です。つまり、基本、**RAGを使わない方が良い結果(NO ANSWERがでない)が出ます**。ただし、今回あえて紹介する理由は、今回の事例を通じて、**Unslothの潜在力はRAGとの相性の悪さと表裏である**ことをわかりやすく示すことができるからです。まずは、パッケージをインストールしましょう。ここは、RAG(Langchain)とUnslothをインストールしましょう。”

```python
# Installs Unsloth, Xformers (Flash Attention) and all other packages!
!pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
!pip install --no-deps "xformers<0.0.27" "trl<0.9.0" peft accelerate bitsandbytes
!pip install langchain chromadb sentence-transformers
!pip install -U langchain-community
```

D先生： “Langchainを使ったんですか？Llama_indexかと思ったのに・・・。”

QEU:FOUNDER ： “はっきりいって、これから紹介する方法はLlama_indexでやっても、全然問題ないですよ。ただし、Llama-indexでは、テストの過程でエラーが頻繁に出たんで、もう疲れたんだわ・・・。次は、「普通に」Unslothのモデルを読み込みます。”

```python
# ----
from unsloth import FastLanguageModel

max_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!
dtype = None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+
load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = "YxBxRyXJx/unsloth_merged_nemo_4bit_0810", # YOUR MODEL YOU USED FOR TRAINING
    max_seq_length = max_seq_length,
    dtype = dtype,
    load_in_4bit = load_in_4bit,
    attn_implementation="flash_attention_2",   
)
FastLanguageModel.for_inference(model)
```

D先生： “これ(unsloth_merged_nemo_4bit)は、前回のタスクで生成したmerged-4bitモデルですね。ちなみに、このモデルは、tranformersでも読み込めますか？”

QEU:FOUNDER ： “Daniel Hanのnotebookによれば、できると思うんだけどね・・・。小生の場合は、いつもエラーが出ます。さてと・・・。次は、LangChainの初期化をしましょう。”

```python
# -----
import re, math
import pandas as pd
import numpy as np
# ---
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader, DirectoryLoader
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from langchain import HuggingFacePipeline
from langchain.chains.question_answering import load_qa_chain
from langchain.prompts import PromptTemplate

# ---
pipe = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=512)
llm = HuggingFacePipeline(pipeline=pipe)
### OKになった！！ ###
```

D先生： “なによ？このコメント！？**「### OKになった！！ ###」**って・・・！！！？？？”

QEU:FOUNDER ： “このパイプラインでエラーが出やすいんですよ。初めは、このパイプラインLLMでエラーが出てきたので、RAGをやることをあきらめていたんです。次にいきましょう。”

```python
# ---
# paths
TXTs_path = 'drive/MyDrive/input_txts'
Embeddings_path =  'drive/MyDrive/input_txts/vectordb'
# ---
# [TXT]Load data
text_loader_kwargs = {'autodetect_encoding': True}
loader = DirectoryLoader(
    TXTs_path,
    glob = "./*.txt",
    loader_cls = TextLoader,
    show_progress = True,
    use_multithreading = True,
    loader_kwargs=text_loader_kwargs
)
documents = loader.load()
# ---
print(f'We have {len(documents)} pages in total')

from langchain.embeddings import HuggingFaceBgeEmbeddings

embeddings = HuggingFaceBgeEmbeddings(
    model_name="BAAI/bge-base-en",
    model_kwargs={'device': 'cuda'},
    encode_kwargs={'normalize_embeddings': True}
)

# ---
# (↓)2回目以降は不要(↓)
# ---
# Split data into chunks
text_splitter = RecursiveCharacterTextSplitter(
   chunk_size = 2000,
   chunk_overlap  = 120,
   length_function = len,
   add_start_index = True,
)
chunks = text_splitter.split_documents(documents)

# ---
# Store data into database
db=Chroma.from_documents(chunks,embedding=embeddings,persist_directory=Embeddings_path)
db.persist()

# ---
# Helper function for printing docs
def pretty_print_docs(docs):
    print(
        f"\n{'-' * 100}\n".join(
            [f"Document {i+1}:\n\n" + d.page_content for i, d in enumerate(docs)]
        )
    )

# ---
# Load the database
vectordb = Chroma(persist_directory=Embeddings_path, embedding_function = embeddings)

# Load the retriver
retriever = vectordb.as_retriever(search_kwargs = {"k" : 3})
query = "Who is Zelensky?"
docs = retriever.invoke(query)
pretty_print_docs(docs)

```

D先生： “RAGデータベースから、プロンプトに類似したChunk(テキスト)を抽出しています。おや？ずいぶん**懐かしい人の名前(Z某)**が質問に入っていますね？”

![imageJRF2-35-3](/2024-08-13-QEUR23_CHRLTM35/imageJRF2-35-3.jpg)

QEU:FOUNDER ： “RAGデータには、UR紛争を含めて過去のプロジェクトのFACT情報が入っています。もちろん、継続保管ですよ。せっかく（データを）作ったのですから・・・。次にいきましょう。今回の本題に入ります。”

```python
# ---
# Inference
from IPython.display import Markdown, display

# ---
# Data Prep
alpaca_prompt = """<s>You are an excellent AI assistant. Below is an instruction that describes a task, paired with an input that provides further information. The instruction and input are question provided by your user. Write a response appropriately your user's question. 

### Instruction:
{}

### Input:
{}

### Context:
{}

If text has been provided in context field (text after '### Context:'), you should refer the information to response. If the answer to the question is not found within the context, you can return "I dont know" as the response.

### Response:
"""
# ----
def create_context(str_instruction, str_input):
    # ---
    # 暫定プロンプトを生成する
    if len(str_input) < 5:
        temp_prompt = f"""
        ### Instruction: {str_instruction}
        """    
    else:
        temp_prompt = f"""
        ### Instruction: {str_instruction}
        
        ### Input: {str_input}
        """
    # ---
    # contextを抽出する
    temp_context = retriever.get_relevant_documents(temp_prompt)
    # page_contentに分解してリストに格納する
    page_contents = [doc.page_content for doc in temp_context]
    comp_string = "context checking..."
    str_context = ""
    #print(page_contents)
    # ---
    # contextを再構成する
    for i in range(len(page_contents)):
        part_contents = page_contents[i]
        if comp_string == part_contents[0:50]:
            print(f"--- temp_context: NO{i} ---")
            print("Duplicated")
        else:
            str_context = str_context + part_contents + "\n\n"
            print(f"--- temp_context: NO{i} ---")
            print(page_contents[i])
            print("\n\n")
        # ---    
        comp_string = part_contents[0:50]

    return str_context

# ----
def comment_correction(str_instruction, str_input):
    # ---
    str_context = create_context(str_instruction, str_input)
    # ---
    inputs = tokenizer(
    [
        alpaca_prompt.format(
            str_instruction, # instruction
            str_input, # input
            str_context, # context
        )
    ], return_tensors = "pt").to("cuda")
    # ---
    outputs = model.generate(**inputs, max_new_tokens = 512, use_cache = True, pad_token_id = tokenizer.eos_token_id)
    list_output = tokenizer.batch_decode(outputs)
    # ---
    str_output = list_output[0]
    str_output = str_output.replace("<s>","")
    str_output = str_output.replace("</s>","")
    return str_output

# ----
# 入出力snippet
str_instruction = "When BRICS was established?"
str_input = ""
response_correct = comment_correction(str_instruction, str_input)
display(Markdown(f"<b>{response_correct}</b>"))

```

D先生： “あれ？このプログラムの構造が、我々が前回に使った推論コードとほぼ同じですね。たしか、RAGの「定石」プロンプトでは、このような複雑なコードにはしないでしょう？”

**(プロンプトのみ再掲)**

```python
alpaca_prompt = """<s>You are an excellent AI assistant. Below is an instruction that describes a task, paired with an input that provides further information. The instruction and input are question provided by your user. Write a response appropriately your user's question. 

### Instruction:
{}

### Input:
{}

### Context:
{}

If text has been provided in context field (text after '### Context:'), you should refer the information to response. If the answer to the question is not found within the context, you can return "I dont know" as the response.

### Response:
"""

```

QEU:FOUNDER ： “そうです。**我々のUnslothモデルの問題は、プロンプトの設計の自由度の高さなのです。逆にメリットでもある**がね。すでにFinetuning段階で、プロンプトに対して、ある程度の枠組みを決めているので、RAGでは（プロンプトを）変えられないんですよ。それでも、敢えてプロンプトを少しだけ変えて推論してみたんですが、パフォーマンズがわるくなります。”

D先生： “たしかに・・・。そういわれて、もう一度プロンプトを見なおすと、FOUNDERはRAG用に微妙にプロンプトを変えています。本来は、Finetuneの段階で変えて、整合性を確保しておくべきですね。”

QEU:FOUNDER ： “ちなみに、今回のプログラムは、**「むりやりRAG法」**でやっています。この部分（↓）のコードを見てください。”

**(CONTEXT抽出部のみを再掲)**

```python
    # ---
    # contextを抽出する
    temp_context = retriever.get_relevant_documents(temp_prompt)
    # page_contentに分解してリストに格納する
    page_contents = [doc.page_content for doc in temp_context]
    comp_string = "context checking..."
    str_context = ""
    #print(page_contents)
    # ---
    # contextを再構成する
    for i in range(len(page_contents)):
        part_contents = page_contents[i]
        if comp_string == part_contents[0:50]:
            print(f"--- temp_context: NO{i} ---")
            print("Duplicated")
        else:
            str_context = str_context + part_contents + "\n\n"
            print(f"--- temp_context: NO{i} ---")
            print(page_contents[i])
            print("\n\n")
        # ---    
        comp_string = part_contents[0:50]

    return str_context
```

D先生： “ほほう・・・。**「retriever.get_relevant_documents」メソッドを使ってCONTEXT用のテキストを抽出したんですね**。”

QEU:FOUNDER ： “そして、その情報をUnslothの推論用プロンプトに貼り付ける。”

D先生： “いやあ、**原始的**・・・（笑）。いや失敬・・・。”

QEU:FOUNDER ： “そうしないとエラーが出まくるんだから、しようがないじゃないですか？理想的には、query_wrapper_prompt関数などを使って、HuggingFaceLLMメソッドで美しくプロンプト情報を入れることはできます。でもね、**なぜかHuggingFaceLLMはUnslothのモデルと相性がわるいんです。**”

![imageJRF2-35-4](/2024-08-13-QEUR23_CHRLTM35/imageJRF2-35-.jpg)

D先生： “llama_indexにしても、LangChainにしても、自分のノウハウとしてプロンプト・エンジニアリングとRAGを矛盾させずにパフォーマンスを上げる方法を持っているはずなんです。でも、今回の方法では、そのノウハウを自分で見出していかなければならない。これは大変だなあ・・・。”

QEU:FOUNDER ： “だ～から、小生は最初に念を押しのよ。Finetuneの基本となる入力フォーマットって、「prompt」と「completion」のたった2種だって・・・。ほとんどの場合、これら2つの情報を入力すれば、finetuneとRAGが最大のパフォーマンスになるように設計しているの、少なくともCohereとかPredibaseは・・・。その一方で、Unslothは、finetuneそのものはとても優秀であり、Reasoningなどの負荷情報を入れられるけど、全てのノウハウを一から開発しなければなりません。”

D先生： “なるほどねえ・・・。何はともあれ、2つぐらいは推論の結果を見たいです。”

**(QUESTION)**

The current global order, dominated by the West, is seen as peaceful and desirable, with the United States acting as the main peacekeeper in conflict zones. However, this perspective overlooks the his-torical and ongoing impacts of colonialism, imperialism, and Western interventionism on global con-flict and instability. How do proponents of this view account for the role of Western powers in creat-ing and sustaining global conflict, and what evidence supports the claim that the current order is peaceful?

西側諸国が支配する現在の世界秩序は、米国が紛争地帯で主要な平和維持活動を行っていることから、平和的で望ましいものとみなされています。しかし、この見方は、植民地主義、帝国主義、西側諸国の介入主義が世界紛争と不安定性に及ぼした歴史的かつ現在も続く影響を見落としています。この見解の支持者は、世界紛争の創出と持続における西側諸国の役割をどのように説明しているのでしょうか。また、現在の秩序が平和的であるという主張を裏付ける証拠は何でしょうか。

**(今回：RAG -plus- finetuning ANSWER)**

The current global order, dominated by the West, is seen as peaceful and desirable, with the United States acting as the main peacekeeper in conflict zones. However, this perspective overlooks the his-torical and ongoing impacts of colonialism, imperialism, and Western interventionism on global con-flict and instability. Proponents of this view may argue that the current order is peaceful because it has prevented major wars between major powers since World War II. They may also point to the role of Western powers in providing humanitarian aid and peacekeeping missions in conflict zones. How-ever, evidence suggests that the current order is not as peaceful as it appears. Western powers have a long history of colonialism and imperialism, which has led to ongoing conflicts and instability in many parts of the world. For example, the United States has been involved in numerous military in-terventions in countries such as Iraq, Afghanistan, and Libya, which have caused significant loss of life and destruction. Additionally, Western powers have often used their economic and political influ-ence to maintain their dominance in the global order, leading to economic inequality and exploitation of resources in developing countries. Therefore, while the current order may appear peaceful on the surface, it is important to consider the historical and ongoing impacts of Western interventionism on global conflict and instability.

西側諸国が支配する現在の世界秩序は、米国が紛争地帯の主な平和維持活動者として機能しており、平和で望ましいと考えられています。しかし、この見方は、植民地主義、帝国主義、西側諸国の介入主義が世界の紛争と不安定性に及ぼした歴史的かつ継続的な影響を見落としています。この見解の支持者は、第二次世界大戦以降、大国間の大規模な戦争を防いできたため、現在の秩序は平和的であると主張するかもしれません。彼らはまた、紛争地帯での人道支援と平和維持活動における西側諸国の役割を指摘するかもしれません。しかし、証拠は、現在の秩序が見た目ほど平和的ではないことを示しています。西側諸国は植民地主義と帝国主義の長い歴史を持ち、それが世界の多くの地域で継続的な紛争と不安定性をもたらしてきました。たとえば、米国はイラク、アフガニスタン、リビアなどの国で数多くの軍事介入に関与しており、それによって多大な人命の損失と破壊を引き起こしてきました。さらに、西側諸国はしばしば経済的、政治的影響力を利用して世界秩序における優位性を維持し、発展途上国における経済格差や資源の搾取を招いてきました。したがって、現在の秩序は表面的には平和に見えるかもしれませんが、西側諸国の介入主義が世界紛争や不安定性に及ぼしている歴史的、そして現在も及ぼしている影響を考慮することが重要です。

**(前回：Finetuneのみ、Mistral Nemo-12b)**

The current global order, dominated by the West, is seen as peaceful and desirable, with the United States acting as the main peacekeeper in conflict zones. However, this perspective overlooks the his-torical and ongoing impacts of colonialism, imperialism, and Western interventionism on global con-flict and instability. Proponents of this view often argue that Western powers have played a positive role in promoting peace and stability, and that the current order is the result of their efforts. Howev-er, evidence suggests that Western powers have often been responsible for creating and sustaining global conflict, and that the current order is far from peaceful.

One example of Western interventionism that has had significant impacts on global conflict is the United States' involvement in the Vietnam War. The war, which lasted from 1955 to 1975, was a re-sult of the United States' efforts to prevent the spread of communism in Southeast Asia. The war re-sulted in the deaths of millions of people, including over 58,000 American soldiers, and led to the de-stabilization of the region. The war also had significant impacts on the United States, including the loss of public support for the war and the rise of anti-war movements.

Another example of Western interventionism that has had significant impacts on global conflict is the United States' involvement in the Iraq War. The war, which began in 2003, was a result of the United States' efforts to remove Saddam Hussein from power and to prevent the spread of weapons of mass destruction. The war resulted in the deaths of hundreds of thousands of people, including over 4,000 American soldiers, and led to the destabilization of the region. The war also had signifi-cant impacts on the United States, including the loss of public support for the war and the rise of an-ti-war movements.

These examples demonstrate that Western powers have often been responsible for creating and sus-taining global conflict, and that the current order is far from peaceful. Proponents of the view that the current order is peaceful and desirable often overlook the historical and ongoing impacts of colo-nialism, imperialism, and Western interventionism on global conflict and instability. It is important to recognize the role of Western powers in creating and sustaining global conflict, and to work to-wards a more peaceful and just global order.

西側諸国が支配する現在の世界秩序は平和で望ましいとみなされており、米国は紛争地帯で主要な平和維持者として機能しています。しかし、この見方は、植民地主義、帝国主義、西側の介入主義が世界の紛争と不安定性に及ぼした歴史的かつ継続的な影響を見落としています。この見解の支持者は、西側諸国が平和と安定を促進する上で積極的な役割を果たしており、現在の秩序は彼らの努力の結果であると主張することがよくあります。しかし、証拠は、西側諸国がしばしば世界紛争を生み出し、維持する責任を負っており、現在の秩序は平和とはほど遠いことを示しています。

世界の紛争に大きな影響を与えた西側の介入主義の1つの例は、米国のベトナム戦争への関与です。1955年から1975年まで続いたこの戦争は、東南アジアでの共産主義の拡大を阻止しようとする米国の努力の結果でした。この戦争により、58,000人以上の米兵を含む数百万人が死亡し、この地域の不安定化につながりました。この戦争は、戦争に対する国民の支持の喪失や反戦運動の台頭など、米国にも大きな影響を及ぼした。

世界の紛争に重大な影響を与えた西側諸国の介入主義のもう 1 つの例は、米国のイラク戦争への関与である。2003 年に始まったこの戦争は、サダム フセインを権力の座から追い出し、大量破壊兵器の拡散を阻止しようとする米国の努力の結果であった。この戦争により、4,000 人を超える米兵を含む数十万人が死亡し、地域の不安定化を招いた。この戦争は、戦争に対する国民の支持の喪失や反戦運動の台頭など、米国にも大きな影響を与えた。

これらの例は、西側諸国がしばしば世界の紛争を生み出し、持続させてきたこと、そして現在の秩序が平和とはほど遠いことを示している。現在の秩序は平和で望ましいという見解を支持する人々は、植民地主義、帝国主義、西側諸国の介入主義が世界の紛争と不安定化に及ぼしてきた歴史的かつ継続的な影響をしばしば見落としている。世界的な紛争を生み出し、それを継続させる西側諸国の役割を認識し、より平和で公正な世界秩序に向けて取り組むことが重要です。

D先生： “RAGを使う場合、語り口が**「一般論に陥らない」**というのが好感を持てますね。”

QEU:FOUNDER ： “おそらく、RAG(Retrieval Argument Generation)が引っ張ってきた記事の影響を受けているんでしょう。もう一つ、「いいもの」を見せます。ドン！！”

**(QUESTION)**

The ASEAN countries' attempts to join the BRICS framework are seen as unwise, but what are the potential benefits and drawbacks of such a move, and how might it impact the regional balance of power and the relationships between the G7, BRICS, and ASEAN nations?

ASEAN諸国がBRICSの枠組みに参加しようとする試みは賢明ではないと見られているが、そのような動きの潜在的な利点と欠点は何だろうか。また、地域の勢力バランスやG7、BRICS、ASEAN諸国の関係にどのような影響を与えるだろうか。

**(今回：FinetuningプラスRAG)**

The potential benefits of ASEAN countries joining BRICS include increased economic cooperation and trade, as well as greater political influence on the global stage. However, there are also potential drawbacks, such as increased competition with existing BRICS members and potential tensions be-tween ASEAN and BRICS countries. The impact on the regional balance of power and relationships between the G7, BRICS, and ASEAN nations would depend on the specific countries involved and their individual goals and priorities.

ASEAN 諸国が BRICS に加盟することで得られる潜在的なメリットとしては、経済協力と貿易の拡大、そして世界舞台での政治的影響力の増大が挙げられます。しかし、既存の BRICS 加盟国との競争の激化や、ASEAN 諸国と BRICS 諸国間の緊張が高まる可能性など、潜在的なデメリットもあります。G7、BRICS、ASEAN 諸国間の地域的な勢力バランスや関係性への影響は、加盟国とその個々の目標や優先事項によって異なります。

**(前回：Finetuningのみ)**

**NO ANSWER**

D先生： “おっと！RAGを使って、LLMが「ボキャブラリ不足」を解決した事例があったんですね！”

QEU:FOUNDER ： “RAGには巨大な潜在力があります。問題は、今回の我々は、それを使いこなしていないことです。それでも、この結果をリリースする理由は何か？この「しゃれこうべ（失敗作）」を道端においておきたいと思ってね。後ろから来る人の道案内にはなるかもしれません。”

D先生： “なぜなら、現在時点、「Unsloth finetuning plus RAG」の事例がWeb上にほとんどない・・・。”

![MOVIE1](http://img.youtube.com/vi/YYUb2TzWKxc/0.jpg)](http://www.youtube.com/watch?v=YYUb2TzWKxc "山口周が語る「文明化の終わった日本」/ビジネスパーソンに求められるアート思考とは何かを探る。")

QEU:FOUNDER ： “小生は、**「道端に落ちているしゃれこうべの数が文明の程度だ」**と思っていますので・・・。”


## ～ まとめ ～

### ・・・ せっかくの機会なので、少し技術的な話をば・・・。 ・・・

D先生： “FOUNDERは、今後、UnslothとPredibaseをどのように使い分けるんですか？”

![imageJRF2-35-5](/2024-08-13-QEUR23_CHRLTM35/imageJRF2-35-5.jpg)

QEU:FOUNDER ： “さあね・・・。普通のケースでは、Predibaseの方がコストが安くなるでしょう。”

D先生： “じゃあ、Unslothが優勢になる、**「キラー・ユースケース」**は何ですか？”

QEU:FOUNDER ： “う～ん、困った・・・。何はともあれ、Unslothは強力なツールなので今後ともUnslothを使うんだが、「キラー・ユースケース」といわれてもねえ・・・。”

D先生： “全然、技術的な議論になっていないじゃないですかあ～。”

QEU:FOUNDER ： “失礼しました（笑）。何はともあれ、Step3後に再度挑戦しますよ。”

